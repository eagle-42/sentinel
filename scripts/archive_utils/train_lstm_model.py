#!/usr/bin/env python3
"""
ğŸš€ Script d'entraÃ®nement du modÃ¨le LSTM pour Sentinel2
EntraÃ®ne le modÃ¨le LSTM avec les donnÃ©es de features techniques
"""

import sys
from pathlib import Path

import numpy as np
import pandas as pd
from loguru import logger

# Ajouter le rÃ©pertoire src au path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from constants import CONSTANTS
from core.prediction import PricePredictor


def train_model(ticker: str = "SPY", epochs: int = 150, use_all_data: bool = True) -> bool:
    """
    EntraÃ®ne le modÃ¨le LSTM SIMPLE pour un ticker donnÃ©

    BasÃ© sur article: "LSTM sans features performe mieux"

    Args:
        ticker: Ticker Ã  entraÃ®ner (ex: SPY)
        epochs: Nombre d'Ã©poques d'entraÃ®nement
        use_all_data: Utiliser TOUTES les donnÃ©es (dÃ©faut: True, recommandÃ© par article)
    """
    try:
        logger.info(f"ğŸš€ DÃ©but de l'entraÃ®nement LSTM SIMPLE (CLOSE ONLY) pour {ticker}")
        logger.info(f"ğŸ“š BasÃ© sur recherche: arXiv:2501.17366v1")

        # Charger les donnÃ©es de features
        features_path = CONSTANTS.get_data_path("features", ticker)
        if not features_path.exists():
            logger.error(f"âŒ Fichier de features non trouvÃ©: {features_path}")
            return False

        logger.info(f"ğŸ“Š Chargement des features depuis {features_path}")
        features_df = pd.read_parquet(features_path)

        # PÃ‰RIODE EXACTE DE L'ARTICLE : Oct 2013 - Sept 2024 (11 ans)
        features_df["DATE"] = pd.to_datetime(features_df["DATE"])

        if not use_all_data:
            # Mode legacy: filtrer sur 3 mois (pour comparaison)
            logger.warning("âš ï¸ Mode legacy: 3 mois seulement (sous-optimal)")
            cutoff = features_df["DATE"].max() - pd.Timedelta(days=90)
            features_df = features_df[features_df["DATE"] >= cutoff].copy()
        else:
            # PÃ©riode 2019-2024 (5 ans rÃ©cents, Ã©vite distribution shift)
            start_date = "2019-01-01"
            end_date = "2024-09-30"
            features_df = features_df[(features_df["DATE"] >= start_date) & (features_df["DATE"] <= end_date)].copy()
            logger.info(f"âœ… PÃ©riode optimale: 2019-2024 (5 ans, prix cohÃ©rents)")

        # FEATURES SÃ‰LECTIONNÃ‰ES (|corr| > 0.5 avec CLOSE)
        # Calculer corrÃ©lations
        numeric_cols = features_df.select_dtypes(include=[np.number]).columns.tolist()
        if "Close" in numeric_cols:
            correlations = features_df[numeric_cols].corr()["Close"].abs()
            selected_features = correlations[correlations > 0.5].index.tolist()

            # Garder DATE + features corrÃ©lÃ©es
            selected_features = ["DATE"] + [f for f in selected_features if f != "Close"] + ["Close"]
            features_df = features_df[selected_features].copy()

            logger.info(f"âœ… Features |corr| > 0.5: {len(selected_features)-2} features + CLOSE")
        else:
            features_df = features_df[["DATE", "Close"]].copy()
            logger.warning("âš ï¸ CLOSE non trouvÃ©, fallback CLOSE only")

        # Forward-fill (variables non-quotidiennes)
        features_df = features_df.fillna(method="ffill")

        # RETURNS au lieu de prix (stationnaritÃ©)
        numeric_cols = features_df.select_dtypes(include=[np.number]).columns.tolist()
        for col in numeric_cols:
            if col != "DATE":
                features_df[f"{col}_RETURN"] = features_df[col].pct_change()

        # Supprimer premiÃ¨re ligne (NaN aprÃ¨s pct_change)
        features_df = features_df.dropna()

        # Renommer CLOSE_RETURN en TARGET
        features_df.rename(columns={"Close_RETURN": "TARGET"}, inplace=True)

        # Normaliser les colonnes en majuscules
        features_df.columns = features_df.columns.str.upper()

        logger.info(f"âœ… Features chargÃ©es: {len(features_df)} lignes, {len(features_df.columns)} colonnes")
        logger.info(f"ğŸ“Š PÃ©riode: {features_df['DATE'].min().date()} â†’ {features_df['DATE'].max().date()}")
        logger.info(f"ğŸ’° Prix moyen: {features_df['CLOSE'].mean():.2f}$ (actuel: {features_df['CLOSE'].iloc[-1]:.2f}$)")

        # Initialiser le prÃ©dicteur
        predictor = PricePredictor(ticker)

        # EntraÃ®ner le modÃ¨le
        logger.info(f"ğŸ§  DÃ©but de l'entraÃ®nement ({epochs} Ã©poques)")
        result = predictor.train(features_df, epochs=epochs)

        if "error" in result:
            logger.error(f"âŒ Erreur d'entraÃ®nement: {result['error']}")
            return False

        # Sauvegarder le modÃ¨le
        model_path = CONSTANTS.get_model_path(ticker) / "version_1" / "model.pkl"
        if predictor.save_model(model_path):
            logger.info(f"âœ… ModÃ¨le sauvegardÃ©: {model_path}")

            # Afficher les mÃ©triques
            logger.info(f"ğŸ“Š MÃ©triques d'entraÃ®nement:")
            logger.info(f"   - Ã‰poques entraÃ®nÃ©es: {result['epochs_trained']}")
            logger.info(f"   - Meilleure validation loss: {result['best_val_loss']:.6f}")
            logger.info(f"   - Mode: CLOSE ONLY (1 feature)")

            return True
        else:
            logger.error("âŒ Ã‰chec de la sauvegarde du modÃ¨le")
            return False

    except Exception as e:
        logger.error(f"âŒ Erreur lors de l'entraÃ®nement: {e}")
        return False


def main():
    """Fonction principale"""
    import argparse

    parser = argparse.ArgumentParser(description="EntraÃ®ner modÃ¨le LSTM SIMPLE (CLOSE ONLY - Article Research)")
    parser.add_argument("--ticker", default="SPY", help="Ticker Ã  entraÃ®ner (dÃ©faut: SPY)")
    parser.add_argument("--epochs", type=int, default=150, help="Nombre d'Ã©poques (dÃ©faut: 150)")
    parser.add_argument(
        "--all-data", action="store_true", default=True, help="Utiliser toutes les donnÃ©es (recommandÃ©)"
    )

    args = parser.parse_args()

    logger.info(f"ğŸš€ === ENTRAÃNEMENT LSTM SIMPLE (RESEARCH-BASED) ===")
    logger.info(f"ğŸ“Š Ticker: {args.ticker}")
    logger.info(f"ğŸ”„ Ã‰poques: {args.epochs}")
    logger.info(f"ğŸ“… DonnÃ©es: {'TOUTES (26 ans)' if args.all_data else '3 mois (legacy)'}")
    logger.info(f"ğŸ“ Features: CLOSE ONLY (sans indicateurs techniques)")

    success = train_model(args.ticker, args.epochs, args.all_data)

    if success:
        logger.info("âœ… EntraÃ®nement terminÃ© avec succÃ¨s!")
        return 0
    else:
        logger.error("âŒ Ã‰chec de l'entraÃ®nement")
        return 1


if __name__ == "__main__":
    sys.exit(main())
