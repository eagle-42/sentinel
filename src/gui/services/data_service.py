"""
Service de donnÃ©es pour Streamlit
Chargement et filtrage des donnÃ©es historiques
"""

import pandas as pd
import numpy as np
from pathlib import Path
from loguru import logger
from typing import Dict, Any, Optional


class DataService:
    """Service de donnÃ©es optimisÃ© pour Streamlit"""
    
    def __init__(self):
        self.data_path = Path("data/historical/yfinance")
        self.cache = {}
        logger.info("ðŸ“Š Service de donnÃ©es initialisÃ©")
    
    def load_data(self, ticker: str) -> pd.DataFrame:
        """Charge les donnÃ©es pour un ticker avec normalisation complÃ¨te"""
        try:
            if ticker in self.cache:
                return self.cache[ticker]
            
            file_path = self.data_path / f"{ticker}_1999_2025.parquet"
            
            if not file_path.exists():
                logger.error(f"âŒ Fichier non trouvÃ©: {file_path}")
                return pd.DataFrame()
            
            # Chargement avec normalisation des colonnes
            df = pd.read_parquet(file_path)
            
            # Normalisation des colonnes (majuscules)
            df.columns = df.columns.str.upper()
            
            # Conversion des dates en UTC pour Ã©viter les dÃ©calages
            if 'DATE' in df.columns:
                df['DATE'] = pd.to_datetime(df['DATE'], utc=True)
            
            # Tri par date pour Ã©viter les "zigzags"
            df = df.sort_values('DATE').reset_index(drop=True)
            
            # Validation des donnÃ©es
            df = self._validate_data(df, ticker)
            
            # Cache pour Ã©viter les rechargements
            self.cache[ticker] = df
            
            logger.info(f"âœ… DonnÃ©es chargÃ©es pour {ticker}: {len(df)} lignes")
            return df
            
        except Exception as e:
            logger.error(f"âŒ Erreur chargement {ticker}: {e}")
            return pd.DataFrame()
    
    def _validate_data(self, df: pd.DataFrame, ticker: str) -> pd.DataFrame:
        """Valide et nettoie les donnÃ©es"""
        if df.empty:
            return df
        
        # VÃ©rifier les colonnes requises
        required_cols = ['DATE', 'CLOSE', 'VOLUME']
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            logger.warning(f"âš ï¸ Colonnes manquantes pour {ticker}: {missing_cols}")
            return pd.DataFrame()
        
        # Nettoyer les valeurs NaN/Inf
        df = df.replace([np.inf, -np.inf], np.nan)
        
        # Supprimer les lignes avec des prix invalides
        df = df.dropna(subset=['CLOSE'])
        
        # VÃ©rifier que les prix sont positifs
        df = df[df['CLOSE'] > 0]
        
        if df.empty:
            logger.error(f"âŒ Aucune donnÃ©e valide pour {ticker}")
            return pd.DataFrame()
        
        logger.info(f"âœ… DonnÃ©es validÃ©es pour {ticker}: {len(df)} lignes valides")
        return df
    
    def filter_by_period(self, df: pd.DataFrame, period: str) -> pd.DataFrame:
        """Filtre les donnÃ©es par pÃ©riode"""
        if df.empty:
            return df
        
        periods = {
            "7 derniers jours": 7,
            "1 mois": 30,
            "3 mois": 90,
            "6 derniers mois": 180,
            "1 an": 365,
            "3 ans": 1095,
            "5 ans": 1825,
            "10 ans": 3650,
            "Total (toutes les donnÃ©es)": None
        }
        
        if period not in periods:
            logger.warning(f"âš ï¸ PÃ©riode inconnue: {period}")
            return df
        
        days = periods[period]
        if days is None:
            return df
        
        # Utiliser la derniÃ¨re date des donnÃ©es comme rÃ©fÃ©rence
        last_date = df['DATE'].max()
        start_date = last_date - pd.Timedelta(days=days)
        
        # Filtrer et trier
        filtered_df = df[df['DATE'] >= start_date].copy()
        filtered_df = filtered_df.sort_values('DATE').reset_index(drop=True)
        
        logger.info(f"âœ… Filtrage {period}: {len(filtered_df)} lignes")
        return filtered_df
    
    def get_available_tickers(self) -> list:
        """Retourne la liste des tickers disponibles"""
        if not self.data_path.exists():
            return []
        
        tickers = []
        for file_path in self.data_path.glob("*.parquet"):
            ticker = file_path.stem.replace("_1999_2025", "")
            tickers.append(ticker)
        
        return sorted(tickers)
